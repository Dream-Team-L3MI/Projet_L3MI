{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9441f702",
   "metadata": {},
   "source": [
    "# PINN pour un circuit RC-AC avec une perte physique \n",
    "### Decomment 2nd block of code for consistent initialising seed\n",
    "### Network trained with dataset used ***without DataLoader***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee972c",
   "metadata": {},
   "source": [
    "<u>Import nécessaire :</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv \n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random seed for model weights and activations\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # If using torch.backends (optional for CPU, more relevant for CUDA)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73775e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A  COMPLETER AVEC LE NOM DU FICHIER CSV\n",
    "df = pd.read_csv( \"rc_ac_results_500K.csv\" )\n",
    "#print(df)\n",
    "print( df.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data normalisation\n",
    "X = df[ [ \"R\" , \"C\" , \"Vin\" , \"Frequency\" ] ].values\n",
    "Y = df[ [ \"Gain_basse\", \"Gain_haute\" , \"Phase_R\" , \"Phase_C\" ] ].values\n",
    "Y_GB = df[ [ \"Gain_basse\" ] ].values\n",
    "Y_GH = df[ [ \"Gain_haute\" ] ].values\n",
    "Y_PR = df[ [ \"Phase_R\" ] ].values\n",
    "Y_PC = df[ [ \"Phase_C\" ] ].values\n",
    "\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "scaler_y_GB = StandardScaler()\n",
    "scaler_y_GH = StandardScaler()\n",
    "scaler_y_PR = StandardScaler()\n",
    "scaler_y_PC = StandardScaler()\n",
    "\n",
    "X_tensor = torch.tensor( scaler_x.fit_transform(X) , dtype = torch.float32 )\n",
    "\n",
    "#######\n",
    "Y_tensor = torch.tensor( scaler_y.fit_transform(Y) , dtype = torch.float32 )\n",
    "#######\n",
    "\n",
    "Y_tensor_GB = torch.tensor( scaler_y_GB.fit_transform(Y_GB) , dtype = torch.float32 )\n",
    "Y_tensor_GH = torch.tensor( scaler_y_GH.fit_transform(Y_GH) , dtype = torch.float32 )\n",
    "Y_tensor_PR = torch.tensor( scaler_y_PR.fit_transform(Y_PR) , dtype = torch.float32 )\n",
    "Y_tensor_PC = torch.tensor( scaler_y_PC.fit_transform(Y_PC) , dtype = torch.float32 )\n",
    "\n",
    "#print(X_tensor[:,0])\n",
    "#print(Y_tensor)\n",
    "\n",
    "dataset = TensorDataset( X_tensor , Y_tensor )\n",
    "\n",
    "dataset_GB = TensorDataset( X_tensor , Y_tensor_GB )\n",
    "dataset_GH = TensorDataset( X_tensor , Y_tensor_GH )\n",
    "dataset_PR = TensorDataset( X_tensor , Y_tensor_PR )\n",
    "dataset_PC = TensorDataset( X_tensor , Y_tensor_PC )\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "R = X_tensor[ :,0 ]\n",
    "C = X_tensor[ :,1 ]\n",
    "Frequency = X_tensor[ :,3 ]\n",
    "print( R )\n",
    "print( C )\n",
    "\n",
    "print( ( R*C ).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8670fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__( self , in_features , out_features = 4 ):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\"\n",
    "        nn.Linear( a , b ) crée une couche fully connected\n",
    "\n",
    "            a : neurones en input\n",
    "            b : neurones en output\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear( in_features , 64 )\n",
    "        self.fc2 = nn.Linear( 64 , 64 )\n",
    "        self.fc3 = nn.Linear( 64 , 64 )\n",
    "        self.fc4 = nn.Linear( 64 , 64 )\n",
    "        self.fc5 = nn.Linear( 64 , 64 )\n",
    "        self.fc6 = nn.Linear( 64 , out_features )\n",
    "        \n",
    "\n",
    "\n",
    "    def forward( self , x ):\n",
    "        x = F.tanh( self.fc1( x ) )\n",
    "        x = F.tanh( self.fc2( x ) )\n",
    "        x = F.tanh( self.fc3( x ) )\n",
    "        x = F.tanh( self.fc4( x ) )\n",
    "        x = F.tanh( self.fc5( x ) )\n",
    "        x = self.fc6( x )  # No activation on output for regression\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 4\n",
    "out_features = 4\n",
    "\n",
    "\n",
    "model = RegressionModel( in_features , out_features )\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam( model.parameters() , lr = 1e-5 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the PDE residual pour gain basse : \n",
    "\n",
    "def pde_residual(model, x, out):\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    x_denorm = torch.tensor(scaler_x.inverse_transform(x.detach().cpu().numpy()), dtype=torch.float32)\n",
    "    u = model(x)\n",
    "\n",
    "    R = x_denorm[:, 0]\n",
    "    C = x_denorm[:, 1]\n",
    "    Vin = x_denorm[:, 2]\n",
    "    Frequency = x_denorm[:, 3]\n",
    "    w = 2 * torch.pi * Frequency\n",
    "\n",
    "    # Calcul de la cible physique selon le nom de sortie\n",
    "    if out == \"Gain_basse\":\n",
    "        u_model = u[:, 0]\n",
    "        u_phys = 1 / torch.sqrt(1 + (w * R * C) ** 2)\n",
    "    elif out == \"Gain_haute\":\n",
    "        u_model = u[:, 1]\n",
    "        u_phys = 1 / torch.sqrt(1 + (w * R * C) ** 2)\n",
    "    elif out == \"Phase_R\":\n",
    "        u_model = u[:, 2]\n",
    "        u_phys = torch.atan(w * R * C)\n",
    "    elif out == \"Phase_C\":\n",
    "        u_model = u[:, 3]\n",
    "        u_phys = -torch.atan(w * R * C)\n",
    "    else:\n",
    "        raise ValueError(\"Sortie non valide.\")\n",
    "\n",
    "    residual = (u_model - u_phys) ** 2\n",
    "    return torch.mean(residual)\n",
    "\n",
    "\n",
    "#pde_test = pde_residual(model, X_tensor)\n",
    "#print(pde_test)\n",
    "#print(pde_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nb_epochs = 200\n",
    "losses_GH = []\n",
    "losses_GB = []\n",
    "losses_PR = []\n",
    "losses_PC = []\n",
    "\n",
    "loss = []\n",
    "# Before training\n",
    "#set_seed(42)\n",
    "model.train()\n",
    "ld = 0.05\n",
    "\n",
    "window = 500  # taille de la moyenne glissante\n",
    "for i in range(nb_epochs):\n",
    "    \n",
    "    for X_batch, Y_batch in loader:\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        X_batch_denorm = torch.tensor(\n",
    "            scaler_x.inverse_transform(X_batch.detach().cpu().numpy()), \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        R = X_batch_denorm[:, 0]\n",
    "        C = X_batch_denorm[:, 1]\n",
    "        Frequency = X_batch_denorm[:, 3]\n",
    "        w = 2 * torch.pi * Frequency\n",
    "\n",
    "        # Physics loss (avec .detach() sur outputs)\n",
    "        #R = X_batch[:, 0]\n",
    "        #C = X_batch[:, 1]\n",
    "        #Frequency = X_batch[:, 3]\n",
    "        #w = 2 * torch.pi * Frequency\n",
    "\n",
    "        gain_basse_th = 1 / torch.sqrt(1 + (w * R * C) ** 2)\n",
    "        gain_haute_th = 1 / torch.sqrt(1 + (w * R * C) ** 2)\n",
    "        phase_R_th = torch.atan(w * R * C)\n",
    "        phase_C_th = -torch.atan(w * R * C)\n",
    "\n",
    "        #loss_physics_GB = ((outputs[:, 0] - gain_basse_th) ** 2).mean()\n",
    "        #loss_physics_GH = ((outputs[:, 1] - gain_haute_th) ** 2).mean()\n",
    "        #loss_physics_PR = ((outputs[:, 2] - phase_R_th) ** 2).mean()\n",
    "        #loss_physics_PC = ((outputs[:, 3] - phase_C_th) ** 2).mean()\n",
    "        # Perte physique via PINN — plus clair et modulaire\n",
    "        loss_physics_GB = pde_residual(model, X_batch, \"Gain_basse\")\n",
    "        loss_physics_GH = pde_residual(model, X_batch, \"Gain_haute\")\n",
    "        loss_physics_PR = pde_residual(model, X_batch, \"Phase_R\")\n",
    "        loss_physics_PC = pde_residual(model, X_batch, \"Phase_C\")\n",
    "\n",
    "        loss_phys = loss_physics_GB + loss_physics_GH + loss_physics_PR + loss_physics_PC\n",
    "\n",
    "        # MSE loss\n",
    "        loss_mse_GB = criterion(outputs[:, 0:1], Y_batch[:, 0:1])\n",
    "        loss_mse_GH = criterion(outputs[:, 1:2], Y_batch[:, 1:2])\n",
    "        loss_mse_PR = criterion(outputs[:, 2:3], Y_batch[:, 2:3])\n",
    "        loss_mse_PC = criterion(outputs[:, 3:4], Y_batch[:, 3:4])\n",
    "\n",
    "        loss_mse = criterion(outputs, Y_batch)\n",
    "\n",
    "        # Total loss par sortie\n",
    "        loss_GB = loss_mse_GB + ld * loss_physics_GB\n",
    "        loss_GH = loss_mse_GH + ld * loss_physics_GH\n",
    "        loss_PR = loss_mse_PR + ld * loss_physics_PR\n",
    "        loss_PC = loss_mse_PC + ld * loss_physics_PC\n",
    "\n",
    "        loss_total_princ = loss_mse + ld * loss_phys\n",
    "\n",
    "        # Backward\n",
    "        total_loss = loss_GB + loss_GH + loss_PR + loss_PC\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        losses_GB.append(loss_GB.item())\n",
    "        losses_GH.append(loss_GH.item())\n",
    "        losses_PR.append(loss_PR.item())\n",
    "        losses_PC.append(loss_PC.item())\n",
    "\n",
    "        loss.append(loss_total_princ.item())\n",
    "\n",
    "        if ( i % 25 == 0 ):\n",
    "            print(f'Epoch [{i+1}], Loss: {loss_GB.item():.9f}')\n",
    "            print(f'Epoch [{i+1}], Loss: {loss_GH.item():.9f}')\n",
    "            print(f'Epoch [{i+1}], Loss: {loss_PR.item():.9f}')\n",
    "            print(f'Epoch [{i+1}], Loss: {loss_PC.item():.9f}')\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Courbes de perte\n",
    "# Gain basse\n",
    "plt.figure()\n",
    "plt.plot(losses_GB, alpha=0.3, label=\"Raw\")\n",
    "plt.plot(pd.Series(losses_GB).rolling(window).mean(), label=\"Smoothed\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Gain Basse')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Gain haute\n",
    "plt.figure()\n",
    "plt.plot(losses_GH, alpha=0.3, label=\"Raw\")\n",
    "plt.plot(pd.Series(losses_GH).rolling(window).mean(), label=\"Smoothed\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Gain Haute')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Phase R\n",
    "plt.figure()\n",
    "plt.plot(losses_PR, alpha=0.3, label=\"Raw\")\n",
    "plt.plot(pd.Series(losses_PR).rolling(window).mean(), label=\"Smoothed\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Phase R')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Phase C\n",
    "plt.figure()\n",
    "plt.plot(losses_PC, alpha=0.3, label=\"Raw\")\n",
    "plt.plot(pd.Series(losses_PC).rolling(window).mean(), label=\"Smoothed\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Phase C')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c902dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Prédictions (N, 4)\n",
    "    predictions = model(X_tensor).cpu().numpy()\n",
    "\n",
    "    # Séparation des colonnes\n",
    "    predictions_GB = predictions[:, 0:1]\n",
    "    predictions_GH = predictions[:, 1:2]\n",
    "    predictions_PR = predictions[:, 2:3]\n",
    "    predictions_PC = predictions[:, 3:4]\n",
    "\n",
    "    # Calcul des pertes\n",
    "    loss_GB = criterion(torch.tensor(predictions_GB), Y_tensor_GB)\n",
    "    loss_GH = criterion(torch.tensor(predictions_GH), Y_tensor_GH)\n",
    "    loss_PR = criterion(torch.tensor(predictions_PR), Y_tensor_PR)\n",
    "    loss_PC = criterion(torch.tensor(predictions_PC), Y_tensor_PC)\n",
    "\n",
    "    print(f\"Loss GB : {loss_GB.item():.3f}\")\n",
    "    print(f\"Loss GH : {loss_GH.item():.3f}\")\n",
    "    print(f\"Loss PR : {loss_PR.item():.3f}\")\n",
    "    print(f\"Loss PC : {loss_PC.item():.3f}\")\n",
    "\n",
    "    # Dénormalisation des prédictions\n",
    "    predictions_original_GB = scaler_y_GB.inverse_transform(predictions_GB)\n",
    "    predictions_original_GH = scaler_y_GH.inverse_transform(predictions_GH)\n",
    "    predictions_original_PR = scaler_y_PR.inverse_transform(predictions_PR)\n",
    "    predictions_original_PC = scaler_y_PC.inverse_transform(predictions_PC)\n",
    "\n",
    "    # Dénormalisation des vraies valeurs\n",
    "    Y_true_original_GB = scaler_y_GB.inverse_transform(Y_tensor_GB.numpy())\n",
    "    Y_true_original_GH = scaler_y_GH.inverse_transform(Y_tensor_GH.numpy())\n",
    "    Y_true_original_PR = scaler_y_PR.inverse_transform(Y_tensor_PR.numpy())\n",
    "    Y_true_original_PC = scaler_y_PC.inverse_transform(Y_tensor_PC.numpy())\n",
    "\n",
    "    # Dénormalisation des fréquences\n",
    "    frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "\n",
    "# Tracé Gain Basse\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(frequencies, Y_true_original_GB[:, 0], label=\"Gain Basse réel\", linewidth=2)\n",
    "plt.plot(frequencies, predictions_original_GB[:, 0], 'o', label=\"Gain Basse Prédit\", markersize=4, color='red')\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Gain en Basse Fréquence\")\n",
    "plt.title(\"Comparaison Gain Basse Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tracé Gain Haute\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(frequencies, Y_true_original_GH[:, 0], label=\"Gain Haute réel\", linewidth=2)\n",
    "plt.plot(frequencies, predictions_original_GH[:, 0], 'o', label=\"Gain Haute Prédit\", markersize=4, color='red')\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Gain en Haute Fréquence\")\n",
    "plt.title(\"Comparaison Gain Haute Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tracé Phase R\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(frequencies, Y_true_original_PR[:, 0], label=\"Phase R réel\", linewidth=2)\n",
    "plt.plot(frequencies, predictions_original_PR[:, 0], 'o', label=\"Phase R Prédit\", markersize=4, color='red')\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Phase R\")\n",
    "plt.title(\"Comparaison Phase R Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tracé Phase C\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(frequencies, Y_true_original_PC[:, 0], label=\"Phase C réel\", linewidth=2)\n",
    "plt.plot(frequencies, predictions_original_PC[:, 0], 'o', label=\"Phase C Prédit\", markersize=4, color='red')\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Phase C\")\n",
    "plt.title(\"Comparaison Phase C Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print( \"Model's state_dict:\" )\n",
    "for param_tensor in model.state_dict():\n",
    "    print( param_tensor, \"\\t\", model.state_dict()[ param_tensor ].size() )\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "\"\"\"print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Defining model name and save the model\n",
    "\n",
    "name = \"My_model\"    # À changer selon l'utilisateur\n",
    "#torch.save( model.state_dict() , name )\n",
    "\n",
    "torch.save(model.state_dict(), \"pinn_RC_AC_transient.pt\")\n",
    "joblib.dump(scaler_x, \"pinn_RC_AC_transient_scaler_X.pkl\")\n",
    "joblib.dump(scaler_y, \"pinn_RC_AC_transient_scaler_y.pkl\")\n",
    "\n",
    "# Load the saved model and evaluate\n",
    "\n",
    "my_model = RegressionModel( in_features , out_features )\n",
    "my_model.load_state_dict( torch.load( name , weights_only = True ) )\n",
    "my_model.eval()\n",
    "\n",
    "# net_pinn.load_state_dict(torch.load(\"pinn_rc_transient.pt\"))\n",
    "# net_pinn.scaler_X = joblib.load(\"pinn_rc_transient_scaler_X.pkl\")\n",
    "# net_pinn.scaler_y = joblib.load(\"pinn_rc_transient_scaler_y.pkl\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    predictions = my_model( X_tensor )  \n",
    "\n",
    "    # Calculate the loss (optional)\n",
    "    lossgh = criterion( predictions , Y_tensor_GH )\n",
    "    lossgb = criterion( predictions , Y_tensor_GB )\n",
    "    losspr = criterion( predictions , Y_tensor_PR )\n",
    "    losspc = criterion( predictions , Y_tensor_PC )\n",
    "    #print( f\"Evaluation Loss: {loss.item():.3f}\" )\n",
    "\n",
    "    print(f\"Evaluation Loss GB after loading: {lossgb.item():.5f}\")\n",
    "    print(f\"Evaluation Loss GH after loading: {lossgh.item():.5f}\")\n",
    "    print(f\"Evaluation Loss PR after loading: {losspr.item():.5f}\")\n",
    "    print(f\"Evaluation Loss PC after loading: {losspc.item():.5f}\")\n",
    "    #print(f\"Epoch {i+1}: total={loss.item():.5f}, mse={loss_mse.item():.5f}, phys={loss_physics.item():.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e29b51",
   "metadata": {},
   "source": [
    "<u>Trier les données par fréquence et moyenner les prédictions pour chaque fréquence </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b3b95",
   "metadata": {},
   "source": [
    "GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dcedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Récupération des fréquences dénormalisées et des valeurs (réelles et prédites)\n",
    "frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "gain_basse_true = Y_true_original_GB[:, 0]\n",
    "gain_basse_pred = predictions_original_GB[:, 0]\n",
    "\n",
    "# Créer un DataFrame pour regrouper et moyenner par fréquence\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Frequency\": frequencies,\n",
    "    \"Gain_basse_true\": gain_basse_true,\n",
    "    \"Gain_basse_pred\": gain_basse_pred\n",
    "})\n",
    "\n",
    "# Regroupement par fréquence (moyenne pour chaque fréquence)\n",
    "df_mean = df_plot.groupby(\"Frequency\").mean().reset_index()\n",
    "\n",
    "# Affichage de la courbe unique\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Gain_basse_true\"], label=\"Gain Basse - Réel\", linewidth=2)\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Gain_basse_pred\"], label=\"Gain Basse - Prédit\", linewidth=2, linestyle='--', color='red')\n",
    "\n",
    "plt.xlabel(\"Fréquence (Hz)\")\n",
    "plt.ylabel(\"Gain en Basse Fréquence\")\n",
    "plt.title(\"Courbes Moyennes Gain Basse Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aae1bc",
   "metadata": {},
   "source": [
    "GH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Récupération des fréquences dénormalisées et des valeurs (réelles et prédites)\n",
    "frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "gain_haute_true = Y_true_original_GH[:, 0]\n",
    "gain_haute_pred = predictions_original_GH[:, 0]\n",
    "\n",
    "# Créer un DataFrame pour regrouper et moyenner par fréquence\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Frequency\": frequencies,\n",
    "    \"Gain_haute_true\": gain_haute_true,\n",
    "    \"Gain_haute_pred\": gain_haute_pred\n",
    "})\n",
    "\n",
    "# Regroupement par fréquence (moyenne pour chaque fréquence)\n",
    "df_mean = df_plot.groupby(\"Frequency\").mean().reset_index()\n",
    "\n",
    "# Affichage de la courbe unique\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Gain_haute_true\"], label=\"Gain Haute - Réel\", linewidth=2)\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Gain_haute_pred\"], label=\"Gain Haute - Prédit\", linewidth=2, linestyle='--', color='red')\n",
    "\n",
    "plt.xlabel(\"Fréquence (Hz)\")\n",
    "plt.ylabel(\"Gain en Haute Fréquence\")\n",
    "plt.title(\"Courbes Moyennes Gain Haute Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883ec39",
   "metadata": {},
   "source": [
    "PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchimport pandas as pd\n",
    "\n",
    "# Récupération des fréquences dénormalisées et des valeurs (réelles et prédites)\n",
    "frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "phase_r_true = Y_true_original_PR[:, 0]\n",
    "phase_r_pred = predictions_original_PR[:, 0]\n",
    "\n",
    "# Créer un DataFrame pour regrouper et moyenner par fréquence\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Frequency\": frequencies,\n",
    "    \"Phase_r_true\": phase_r_true,\n",
    "    \"Phase_r_pred\": phase_r_pred\n",
    "})\n",
    "\n",
    "# Regroupement par fréquence (moyenne pour chaque fréquence)\n",
    "df_mean = df_plot.groupby(\"Frequency\").mean().reset_index()\n",
    "\n",
    "# Affichage de la courbe unique\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Phase_r_true\"], label=\"Phase R - Réel\", linewidth=2)\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Phase_r_pred\"], label=\"Phase R - Prédit\", linewidth=2, linestyle='--', color='red')\n",
    "\n",
    "plt.xlabel(\"Fréquence (Hz)\")\n",
    "plt.ylabel(\"Phase R Fréquence\")\n",
    "plt.title(\"Courbes Moyennes Phase R Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24041b2c",
   "metadata": {},
   "source": [
    "PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8737088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Récupération des fréquences dénormalisées et des valeurs (réelles et prédites)\n",
    "frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "phase_c_true = Y_true_original_PC[:, 0]\n",
    "phase_c_pred = predictions_original_PC[:, 0]\n",
    "\n",
    "# Créer un DataFrame pour regrouper et moyenner par fréquence\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Frequency\": frequencies,\n",
    "    \"Phase_c_true\": phase_c_true,\n",
    "    \"Phase_c_pred\": phase_c_pred\n",
    "})\n",
    "\n",
    "# Regroupement par fréquence (moyenne pour chaque fréquence)\n",
    "df_mean = df_plot.groupby(\"Frequency\").mean().reset_index()\n",
    "\n",
    "# Affichage de la courbe unique\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Phase_c_true\"], label=\"Phase C - Réel\", linewidth=2)\n",
    "plt.plot(df_mean[\"Frequency\"], df_mean[\"Phase_c_pred\"], label=\"Phase C - Prédit\", linewidth=2, linestyle='--', color='red')\n",
    "\n",
    "plt.xlabel(\"Fréquence (Hz)\")\n",
    "plt.ylabel(\"Phase C Fréquence\")\n",
    "plt.title(\"Courbes Moyennes Phase C Réel vs Prédit\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
