{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9441f702",
   "metadata": {},
   "source": [
    "# PINN pour un circuit RC-AC avec une perte physique \n",
    "### Decomment 2nd block of code for consistent initialising seed\n",
    "### Network trained with dataset used ***without DataLoader***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d319d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ee972c",
   "metadata": {},
   "source": [
    "<u>Import nécessaire :</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv \n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random seed for model weights and activations\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # If using torch.backends (optional for CPU, more relevant for CUDA)\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73775e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A  COMPLETER AVEC LE NOM DU FICHIER CSV\n",
    "df = pd.read_csv(\"rc_ac_results_800.csv\")\n",
    "#print(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data normalisation\n",
    "X = df[ [ \"R\" , \"C\" , \"Vin\" , \"Frequency\" ] ].values\n",
    "Y = df[ [ \"Magnitude\", \"Phase\" ] ].values\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_tensor = torch.tensor( scaler_x.fit_transform(X) , dtype = torch.float32 )\n",
    "Y_tensor = torch.tensor( scaler_y.fit_transform(Y) , dtype = torch.float32 )\n",
    "\n",
    "#print(X_tensor[:,0])\n",
    "#print(Y_tensor)\n",
    "\n",
    "dataset = TensorDataset( X_tensor , Y_tensor )\n",
    "\n",
    "#loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "R = X_tensor[:,0]\n",
    "C = X_tensor[:,1]\n",
    "Frequency = X_tensor[:,3]\n",
    "print( R )\n",
    "print( C )\n",
    "\n",
    "print( ( R*C ).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8670fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__( self , in_features , out_features = 2 ):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\"\n",
    "        nn.Linear( a , b ) crée une couche fully connected\n",
    "\n",
    "            a : neurones en input\n",
    "            b : neurones en output\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear( in_features , 8 )\n",
    "        self.fc2 = nn.Linear( 8 , 16 )\n",
    "        self.fc3 = nn.Linear( 16 , 64 )\n",
    "        self.fc4 = nn.Linear( 64 , 32 )\n",
    "        self.fc5 = nn.Linear( 32 , 8 )\n",
    "        self.fc6 = nn.Linear( 8 , 2 )\n",
    "        \n",
    "\n",
    "\n",
    "    def forward( self , x ):\n",
    "        x = F.relu( self.fc1( x ) )\n",
    "        x = F.relu( self.fc2( x ) )\n",
    "        x = F.relu( self.fc3( x ) )\n",
    "        x = F.relu( self.fc4( x ) )\n",
    "        x = F.relu( self.fc5( x ) )\n",
    "        x = self.fc6( x )  # No activation on output for regression\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 4\n",
    "out_features = 2\n",
    "\n",
    "\n",
    "model = RegressionModel( in_features , out_features )\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam( model.parameters() , lr = 0.001 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the PDE residual: \n",
    "\n",
    "def pde_residual( model , x ):\n",
    "    # Make sure x is set to require gradients for derivative calculations.\n",
    "    x = x.clone().detach().requires_grad_( True )\n",
    "    u = model( x )\n",
    "    \n",
    "    #t = x[ :, 0]\n",
    "    # Compute the first derivative, du/dt.\n",
    "    #u_x = ( torch.autograd.grad( u , t , grad_outputs = torch.ones_like(u) , create_graph = True )[ 0 ] )[ :,0 ]\n",
    "    \n",
    "    \"\"\"print( u_x.shape )\n",
    "    print( x.shape )\n",
    "    print( u[:,0].shape )\"\"\"\n",
    "\n",
    "    R = x[:, 0]\n",
    "    C = x[:, 1]\n",
    "    Vin = x[:, 2]\n",
    "    Frequency = x[:, 3]\n",
    "    w = 2 * torch.pi * Frequency\n",
    "\n",
    "    mag = u[ :, 0 ]\n",
    "    phase = u[ :, 1 ]\n",
    "\n",
    "    \"\"\"print(R.shape)\n",
    "    print(C.shape)\n",
    "    print(U.shape)\"\"\"\n",
    "\n",
    "    # Formules physiques\n",
    "    mag_2 = 1 / torch.sqrt( 1 + ( w * R * C ) ** 2 )\n",
    "    phase_2 = -torch.atan( w * R * C )\n",
    "\n",
    "    \n",
    "    residual_mag = (mag - mag_2 ) ** 2\n",
    "    residual_phase = (phase - phase_2 ) ** 2\n",
    "    residual = ( residual_mag + residual_phase )\n",
    "    return torch.mean( residual )\n",
    "\n",
    "\n",
    "#pde_test = pde_residual(model, X_tensor)\n",
    "#print(pde_test)\n",
    "#print(pde_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 300\n",
    "losses = []\n",
    "# Before training\n",
    "#set_seed(42)\n",
    "model.train()\n",
    "for i in range(nb_epochs):\n",
    "    \"\"\"\n",
    "        for X_batch, Y_batch in loader:\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Physics loss\n",
    "    loss_physics = pde_residual( model , X_tensor )\n",
    "\n",
    "    # MSE loss\n",
    "    outputs = model( X_tensor )\n",
    "    loss_mse = criterion( outputs , Y_tensor ) \n",
    "\n",
    "    # final loss\n",
    "    loss = loss_mse + loss_physics\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append( loss.item() )\n",
    "\n",
    "\n",
    "    print( f'Epoch [{i+ 1}], Loss: {loss.item():.9f}' )\n",
    "\n",
    "# Plot the loss curve\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c902dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# No gradient calculation during evaluation\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    predictions = model( X_tensor )  # Assuming X_tensor is your input data\n",
    "\n",
    "    # Calculate the loss (optional)\n",
    "    loss = criterion( predictions , Y_tensor )\n",
    "    print( f\"Evaluation Loss: {loss.item():.3f}\" )\n",
    "\n",
    "    predictions_original = scaler_y.inverse_transform( predictions.numpy() )\n",
    "\n",
    "    # Print the inverse transformed predictions\n",
    "    print( \"Inverse Predictions: \\n\", predictions_original )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dénormalisation des prédictions et des vraies valeurs\n",
    "predictions_original = scaler_y.inverse_transform(predictions.numpy())\n",
    "Y_true_original = scaler_y.inverse_transform(Y_tensor.numpy())\n",
    "\n",
    "# Dénormalisation de la fréquence\n",
    "frequencies = scaler_x.inverse_transform(X_tensor.numpy())[:, 3]\n",
    "\n",
    "# Tracé magnitude réelle vs prédite\n",
    "plt.figure( figsize = ( 10 , 5 ) )\n",
    "plt.plot( frequencies, Y_true_original[:, 0] , label=\"True Magnitude\" , linewidth=2 )\n",
    "plt.plot( frequencies, predictions_original[:, 0] , 'o' , label=\"Predicted Magnitude\" , markersize=4 , color='red' )\n",
    "\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Magnitude\")\n",
    "plt.title(\"Magnitude vs Frequency (données réelles)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618853cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model's state_dict\n",
    "print( \"Model's state_dict:\" )\n",
    "for param_tensor in model.state_dict():\n",
    "    print( param_tensor, \"\\t\", model.state_dict()[param_tensor].size() )\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "\"\"\"print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ea9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name and save the model\n",
    "\n",
    "name = \"My_model\"    # À changer selon l'utilisateur\n",
    "torch.save( model.state_dict() , name )\n",
    "\n",
    "# Load the saved model and evaluate\n",
    "\n",
    "my_model = RegressionModel( in_features , out_features )\n",
    "my_model.load_state_dict( torch.load( name , weights_only = True ) )\n",
    "my_model.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass\n",
    "    predictions = my_model( X_tensor )  \n",
    "\n",
    "    # Calculate the loss (optional)\n",
    "    loss = criterion( predictions , Y_tensor )\n",
    "    #print( f\"Evaluation Loss: {loss.item():.3f}\" )\n",
    "\n",
    "    print(f\"Evaluation Loss after loading: {loss.item():.5f}\")\n",
    "    #print(f\"Epoch {i+1}: total={loss.item():.5f}, mse={loss_mse.item():.5f}, phys={loss_physics.item():.5f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
