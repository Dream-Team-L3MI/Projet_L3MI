{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491bddd5",
   "metadata": {},
   "source": [
    "Import des bibliothèques python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd43dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv \n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3c751",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b764b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X   Y   Z  res\n",
      "0    1   2   3    1\n",
      "1    2   3   4    2\n",
      "2    3   2   1    3\n",
      "3    2   1   2    2\n",
      "4    5   1   1    5\n",
      "5    4   1   2    4\n",
      "6   10   1   0   10\n",
      "7   11   7   6   11\n",
      "8   15   9   8   15\n",
      "9   20   9   1   20\n",
      "10  13   3   3   13\n",
      "11   3   4   5    3\n",
      "12   5  13   3    5\n",
      "13  17  16  16   17\n",
      "(14, 4)\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 2.,  3.,  4.],\n",
      "        [ 3.,  2.,  1.],\n",
      "        [ 2.,  1.,  2.],\n",
      "        [ 5.,  1.,  1.],\n",
      "        [ 4.,  1.,  2.],\n",
      "        [10.,  1.,  0.],\n",
      "        [11.,  7.,  6.],\n",
      "        [15.,  9.,  8.],\n",
      "        [20.,  9.,  1.],\n",
      "        [13.,  3.,  3.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 5., 13.,  3.],\n",
      "        [17., 16., 16.]]) \n",
      " tensor([ 1.,  2.,  3.,  2.,  5.,  4., 10., 11., 15., 20., 13.,  3.,  5., 17.])\n"
     ]
    }
   ],
   "source": [
    "#1)Importation de pandas et lecture du fichier csv \n",
    "#on charge le fichier dtb.csv dans un dataframe(structure tabulaire) pandas \"df\"\n",
    "df = pd.read_csv(\"dtb.csv\")\n",
    "#puis on affiche son contenu \n",
    "print(df)\n",
    "#on affiche la dimension (nbr de lignes et de colonnes)\n",
    "print(df.shape)\n",
    "\n",
    "#2)Définir une class Dataset personnalisé \n",
    "#hérité de torch.utils.data.Dataset avec laquelle on peut créer un jeu de données \n",
    "class DtSet(Dataset):\n",
    "    #on initialise l'objet\n",
    "    def __init__(self, dataframe):\n",
    "        #on selectionne toutes les colonnes sauf la ddernière et on recupère leurs valeurs(tableau)\n",
    "        self.x = torch.tensor(dataframe.iloc[:, :-1].values, dtype=torch.float32)\n",
    "        #on va sélectionner seulemenet la derr colonne qui est souvent la cible \n",
    "        self.y = torch.tensor(dataframe.iloc[:, -1].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    #ccette methode permet de recuperer un elem individuel à partir d'un dataset\n",
    "    #elle prend un indice en entrée et renvoie la paire x,y \n",
    "    def __getitem__(self, ind):\n",
    "        return self.x[ind], self.y[ind]\n",
    "#creation de l'instance    \n",
    "instance = DtSet(df)\n",
    "#dataloader est un utilitaire pytorch qui permet de faire des batches \n",
    "#avec l'objet , la taille du lot (3 par exemple) et shuffle true permet de melanger les données\n",
    "loader = torch.utils.data.DataLoader(instance, batch_size=3, shuffle=True)\n",
    "\n",
    "print(instance.x, \"\\n\",  instance.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f25ee",
   "metadata": {},
   "source": [
    "Mauvaise Normalisation des données (Z - score) (creation of noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf2445c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for X, Y in loader:\\n    mean = X.mean()\\n    std = X.std()\\n    X = (X - mean) / std'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"for X, Y in loader:\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    X = (X - mean) / std\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd62367c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47571929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1402, -0.6661, -0.2348],\n",
      "        [-0.9757, -0.4541,  0.0181],\n",
      "        [-0.8111, -0.6661, -0.7406],\n",
      "        [-0.9757, -0.8780, -0.4877],\n",
      "        [-0.4820, -0.8780, -0.7406],\n",
      "        [-0.6465, -0.8780, -0.4877],\n",
      "        [ 0.3409, -0.8780, -0.9935],\n",
      "        [ 0.5055,  0.3936,  0.5238],\n",
      "        [ 1.1637,  0.8174,  1.0296],\n",
      "        [ 1.9866,  0.8174, -0.7406],\n",
      "        [ 0.8346, -0.4541, -0.2348],\n",
      "        [-0.8111, -0.2422,  0.2709],\n",
      "        [-0.4820,  1.6651, -0.2348],\n",
      "        [ 1.4929,  2.3009,  3.0526]]) \n",
      " tensor([[-1.1402],\n",
      "        [-0.9757],\n",
      "        [-0.8111],\n",
      "        [-0.9757],\n",
      "        [-0.4820],\n",
      "        [-0.6465],\n",
      "        [ 0.3409],\n",
      "        [ 0.5055],\n",
      "        [ 1.1637],\n",
      "        [ 1.9866],\n",
      "        [ 0.8346],\n",
      "        [-0.8111],\n",
      "        [-0.4820],\n",
      "        [ 1.4929]])\n"
     ]
    }
   ],
   "source": [
    "# True normalisation (Z - score)\n",
    "#on extrait les  données  x,y,z du dataframe \n",
    "X = df[[\"X\", \"Y\", \"Z\"]].values #(input)\n",
    "#on extrait la colonne res qui est la cible dans ce cas (output)\n",
    "Y = df[[\"res\"]].values\n",
    "#on crée deux normalisateurs Z-score \n",
    "#la methode z-score va transformer chaque valeur selon x_norm= x−μ/σ \n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "#Transformation et conversion en tensors pytorch \n",
    "\"\"\"\n",
    "fit_transform : \n",
    "    fit calcule la moyenne et l'écart-type sur les données\n",
    "    transform applique la normalisation Z-score\n",
    "\"\"\"\n",
    "X_tensor = torch.tensor(scaler_x.fit_transform(X), dtype = torch.float32)\n",
    "Y_tensor = torch.tensor(scaler_y.fit_transform(Y), dtype = torch.float32)\n",
    "\n",
    "\n",
    "print(X_tensor, \"\\n\", Y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89730df8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c4fbd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, 3),\n",
    "        self.linear = nn.Linear(3, 6),\n",
    "        self.linear = nn.Linear(6, 6),\n",
    "        self.linear = nn.Linear(6, 9),\n",
    "        self.linear = nn.Linear(9, 12),\n",
    "        self.linear = nn.Linear(12, 12),\n",
    "        self.linear = nn.Linear(12, 9),\n",
    "        self.linear = nn.Linear(9, 9),\n",
    "        self.linear = nn.Linear(9, 7),\n",
    "        self.linear = nn.Linear(7, 5),\n",
    "        self.linear = nn.Linear(5, 3),\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d57211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 3 \n",
    "out_features = 1\n",
    "# régression linéaire simple\n",
    "model = LinRegModel(in_features, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d0c0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error comme fonction de perte\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Stochastic Gradient Descent (SGD) avec un learning rate de 0.1.\n",
    "\"\"\" \n",
    "model.parameters() récupère tous les poids (et biais) entraînables\n",
    "\"\"\"\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd7f268",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b2a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Loss: 0.540813744\n",
      "Epoch [2], Loss: 0.331718385\n",
      "Epoch [3], Loss: 0.227787837\n",
      "Epoch [4], Loss: 0.166408136\n",
      "Epoch [5], Loss: 0.125341102\n",
      "Epoch [6], Loss: 0.095822297\n",
      "Epoch [7], Loss: 0.073818192\n",
      "Epoch [8], Loss: 0.057119720\n",
      "Epoch [9], Loss: 0.044331007\n",
      "Epoch [10], Loss: 0.034485806\n",
      "Epoch [11], Loss: 0.026881406\n",
      "Epoch [12], Loss: 0.020993546\n",
      "Epoch [13], Loss: 0.016425831\n",
      "Epoch [14], Loss: 0.012876294\n",
      "Epoch [15], Loss: 0.010113747\n",
      "Epoch [16], Loss: 0.007960592\n",
      "Epoch [17], Loss: 0.006280036\n",
      "Epoch [18], Loss: 0.004966487\n",
      "Epoch [19], Loss: 0.003938301\n",
      "Epoch [20], Loss: 0.003132242\n",
      "Epoch [21], Loss: 0.002499285\n",
      "Epoch [22], Loss: 0.002001361\n",
      "Epoch [23], Loss: 0.001608891\n",
      "Epoch [24], Loss: 0.001298877\n",
      "Epoch [25], Loss: 0.001053403\n",
      "Epoch [26], Loss: 0.000858509\n",
      "Epoch [27], Loss: 0.000703318\n",
      "Epoch [28], Loss: 0.000579338\n",
      "Epoch [29], Loss: 0.000479934\n",
      "Epoch [30], Loss: 0.000399918\n",
      "Epoch [31], Loss: 0.000335233\n",
      "Epoch [32], Loss: 0.000282700\n",
      "Epoch [33], Loss: 0.000239823\n",
      "Epoch [34], Loss: 0.000204642\n",
      "Epoch [35], Loss: 0.000175618\n",
      "Epoch [36], Loss: 0.000151535\n",
      "Epoch [37], Loss: 0.000131435\n",
      "Epoch [38], Loss: 0.000114558\n",
      "Epoch [39], Loss: 0.000100302\n",
      "Epoch [40], Loss: 0.000088189\n",
      "Epoch [41], Loss: 0.000077837\n",
      "Epoch [42], Loss: 0.000068940\n",
      "Epoch [43], Loss: 0.000061252\n",
      "Epoch [44], Loss: 0.000054575\n",
      "Epoch [45], Loss: 0.000048748\n",
      "Epoch [46], Loss: 0.000043640\n",
      "Epoch [47], Loss: 0.000039144\n",
      "Epoch [48], Loss: 0.000035172\n",
      "Epoch [49], Loss: 0.000031651\n",
      "Epoch [50], Loss: 0.000028520\n",
      "Epoch [51], Loss: 0.000025729\n",
      "Epoch [52], Loss: 0.000023234\n",
      "Epoch [53], Loss: 0.000020999\n",
      "Epoch [54], Loss: 0.000018993\n",
      "Epoch [55], Loss: 0.000017190\n",
      "Epoch [56], Loss: 0.000015567\n",
      "Epoch [57], Loss: 0.000014104\n",
      "Epoch [58], Loss: 0.000012784\n",
      "Epoch [59], Loss: 0.000011592\n",
      "Epoch [60], Loss: 0.000010514\n",
      "Epoch [61], Loss: 0.000009539\n",
      "Epoch [62], Loss: 0.000008656\n",
      "Epoch [63], Loss: 0.000007857\n",
      "Epoch [64], Loss: 0.000007132\n",
      "Epoch [65], Loss: 0.000006476\n",
      "Epoch [66], Loss: 0.000005880\n",
      "Epoch [67], Loss: 0.000005340\n",
      "Epoch [68], Loss: 0.000004850\n",
      "Epoch [69], Loss: 0.000004405\n",
      "Epoch [70], Loss: 0.000004001\n",
      "Epoch [71], Loss: 0.000003635\n",
      "Epoch [72], Loss: 0.000003302\n",
      "Epoch [73], Loss: 0.000003000\n",
      "Epoch [74], Loss: 0.000002725\n",
      "Epoch [75], Loss: 0.000002476\n",
      "Epoch [76], Loss: 0.000002250\n",
      "Epoch [77], Loss: 0.000002044\n",
      "Epoch [78], Loss: 0.000001857\n",
      "Epoch [79], Loss: 0.000001688\n",
      "Epoch [80], Loss: 0.000001533\n",
      "Epoch [81], Loss: 0.000001393\n",
      "Epoch [82], Loss: 0.000001266\n",
      "Epoch [83], Loss: 0.000001150\n",
      "Epoch [84], Loss: 0.000001045\n",
      "Epoch [85], Loss: 0.000000950\n",
      "Epoch [86], Loss: 0.000000863\n",
      "Epoch [87], Loss: 0.000000784\n",
      "Epoch [88], Loss: 0.000000713\n",
      "Epoch [89], Loss: 0.000000648\n",
      "Epoch [90], Loss: 0.000000589\n",
      "Epoch [91], Loss: 0.000000535\n",
      "Epoch [92], Loss: 0.000000486\n",
      "Epoch [93], Loss: 0.000000442\n",
      "Epoch [94], Loss: 0.000000401\n",
      "Epoch [95], Loss: 0.000000365\n",
      "Epoch [96], Loss: 0.000000331\n",
      "Epoch [97], Loss: 0.000000301\n",
      "Epoch [98], Loss: 0.000000274\n",
      "Epoch [99], Loss: 0.000000249\n",
      "Epoch [100], Loss: 0.000000226\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 100 # nombre d’itérations\n",
    "\n",
    "for i in range(nb_epochs):\n",
    "    # Propagation avant\n",
    "    \"\"\"\n",
    "    calcule de la sortie prédite en appliquant la régression linéaire.\n",
    "    \"\"\"\n",
    "    outputs = model(X_tensor) \n",
    "\n",
    "    # fonction de perte (loss)\n",
    "    # Compare les sorties prédites outputs avec les vraies valeurs Y_tensor.\n",
    "    loss = criterion(outputs, Y_tensor) \n",
    "\n",
    "    # Remise à zéro des gradients précédents pour éviter l'accumulation des gradients d’itérations précédentes.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Mise à jour des paramètres du modèle selon les gradients et la règle d’optimisation\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{i+ 1}], Loss: {loss.item():.9f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52214003",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c1f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted for X = [[5223    1 2025]]: 5220.447265625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_x = np.array([[5223, 1, 2025]])\n",
    "\n",
    "scalar_test = StandardScaler()\n",
    "\n",
    "new_x_tensor = torch.tensor((new_x), dtype = torch.float32)\n",
    "\n",
    "model.eval() # Évite les effets indésirables si ton modèle avait des couches comme Dropout ou BatchNorm.\n",
    "\n",
    "with torch.no_grad(): # Évite de stocker les gradients (inutiles ici), donc plus rapide et moins de mémoire\n",
    "    prediction_norm = model(new_x_tensor)\n",
    "\n",
    "prediction_denorm = prediction_norm.item() \n",
    "\n",
    "print(f\"Predicted for X = {new_x}: {(prediction_denorm)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
